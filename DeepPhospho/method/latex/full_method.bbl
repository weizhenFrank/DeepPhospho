\begin{thebibliography}{1}\itemsep=-1pt

\bibitem{gessulat2019prosit}
Siegfried Gessulat, Tobias Schmidt, Daniel~Paul Zolg, Patroklos Samaras,
  Karsten Schnatbaum, Johannes Zerweck, Tobias Knaute, Julia Rechenberger,
  Bernard Delanghe, Andreas Huhmer, et~al.
\newblock Prosit: proteome-wide prediction of peptide tandem mass spectra by
  deep learning.
\newblock {\em Nature methods}, 16(6):509--518, 2019.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{kingma2017adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization, 2017.

\bibitem{ma2018improved}
Chunwei Ma, Yan Ren, Jiarui Yang, Zhe Ren, Huanming Yang, and Siqi Liu.
\newblock Improved peptide retention time prediction in liquid chromatography
  through deep learning.
\newblock {\em Analytical chemistry}, 90(18):10881--10888, 2018.

\bibitem{sabour2017dynamic}
Sara Sabour, Nicholas Frosst, and Geoffrey~E Hinton.
\newblock Dynamic routing between capsules.
\newblock In {\em Advances in neural information processing systems}, pages
  3856--3866, 2017.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem{xiong2020layer}
Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing,
  Huishuai Zhang, Yanyan Lan, Liwei Wang, and Tie-Yan Liu.
\newblock On layer normalization in the transformer architecture, 2020.

\bibitem{zeng2019ms}
Wen-Feng Zeng, Xie-Xuan Zhou, Wen-Jing Zhou, Hao Chi, Jianfeng Zhan, and Si-Min
  He.
\newblock Ms/ms spectrum prediction for modified peptides using pdeep2 trained
  by transfer learning.
\newblock {\em Analytical chemistry}, 91(15):9724--9731, 2019.

\end{thebibliography}
